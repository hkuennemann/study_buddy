{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096f9752",
   "metadata": {},
   "source": [
    "# Study Buddy - Showcase Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d12663",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "579b6251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendrik/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2384ad38",
   "metadata": {},
   "source": [
    "## Load and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472dc0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get FILE_PATH\n",
    "file_path = os.getenv(\"FILE_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434222c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_q, docs_a = load_and_split(file_path, suppress_warnings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35512085",
   "metadata": {},
   "source": [
    "## Generating Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4266ba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761226495.426608  382694 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "/Users/hendrik/Documents/Studium/Additional Education/study_buddy/src/generating_questions.py:153: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return chain.run(docs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert at creating practice questions based on study material.\n",
      "Your goal is to prepare a student for their exam. \n",
      "You do this by asking questions about the text below:\n",
      "\n",
      "------------\n",
      "ADVANCED DATA ANALYTICS – STUDY NOTES        Introduc)on to Big Data ................................................................................................................. 4 Programming for data analysis ....................................................................................................... 5 General ....................................................................................................................................... 5 Pandas ........................................................................................................................................ 5 General processing operta)ons .............................................................................................. 5 Combining DataFrames .......................................................................................................... 6 Time-series ............................................................................................................................. 8 Moving Averages ................................................................................................................ 8 Simple Moving Average .................................................................................................. 8 Weighted Moving Average ............................................................................................. 8 Correla)ons ........................................................................................................................ 9 ShiJed correla)on .......................................................................................................... 9 Parallel and Distributed framework ............................................................................................ 9 Programming with (Apache) Spark ........................................................................................... 10 Tables and Selec)on ............................................................................................................. 10 Aggrega)on .......................................................................................................................... 11 Nested Selects ...................................................................................................................... 11 Windows (e.g. Moving Average) ........................................................................................... 11 Join ....................................................................................................................................... 12 Miscellaneous ........................................................................................................................... 12 Wide and Long format .......................................................................................................... 12 Unstack ................................................................................................................................. 12Introduc)on to Machine Learning ................................................................................................ 12 Supervised Learning ................................................................................................................. 13 Regression ............................................................................................................................ 13 OverﬁZng ............................................................................................................................. 13 Errors Overview .................................................................................................................... 14 Valida)on and Selec)on ....................................................................................................... 14 Holdout method ............................................................................................................... 14 K-fold cross-valida)on ...................................................................................................... 14 Bootstrapping ................................................................................................................... 14 Wild Bootstrapping ........................................................................................................... 14 The logis)c model ................................................................................................................. 15 Mul)variate Regression ........................................................................................................ 16 Regression Summary ............................................................................................................ 16 Regulariza)on ....................................................................................................................... 16 Dimensionality Reduc)on ..................................................................................................... 17 Principal Component Analysis (PCA) ................................................................................ 17 t-Distributed Stochas)c Neighbor Embedding (tSNE) ...................................................... 18 Classiﬁca)on ......................................................................................................................... 18 Maximum margin classiﬁer ............................................................................................... 19 Kernel Trick ....................................................................................................................... 19 Unsupervised Learning ............................................................................................................. 19 Classiﬁca)on vs. clustering ................................................................................................... 19 Clustering .............................................................................................................................. 19 Types of clustering ............................................................................................................ 20 Algorithms: K-means ........................................................................................................ 20 Clustering valida)on: Silhouece Score ............................................................................. 21 Number of clusters ........................................................................................................... 21 Clustering @Spark ............................................................................................................ 21 Graph Algorithms ................................................................................................................. 22 Dijkstra – Shortest Path Problem ...................................................................................... 22 Compute importance of web pages – PageRank .............................................................. 22 Connected components .................................................................................................... 23 Community detec)on ....................................................................................................... 23Maximum-Flow ................................................................................................................. 23 Graphs in Spark ................................................................................................................. 24 Introduc)on to cloud-based Data Analysis ecosystems ............................................................... 24 CPUs, GPUs, TPUs and data analysis ......................................................................................... 24 Data analysis/processing models .............................................................................................. 25 Data storages ............................................................................................................................ 25 Privacy-preserving Data Analysis .................................................................................................. 26 Security of data in public cloud ................................................................................................ 26 Privacy-preserving data sharing ................................................................................................ 26 K-anonymity ......................................................................................................................... 27 Diﬀeren)al privacy................................................................................................................ 27 Privacy-preserving computa)on ............................................................................................... 27 Mul)-party computa)on ...................................................................................................... 27 Homomorphic encryp)on .................................................................................................... 28Introduction to Big Data  To extract the knowledge (and value), data needs to be - Collected - Stored - Managed - Analyzed  Analytics: The science that analyze crude data to extract useful knowledge from them.  Discover patterns and models that are: o Valid: hold on new data with some certainty o Useful: should be possible to act on the item o Unexpected: non-obvious to the system o Understandable: humans should be able to interpret the pattern  Machine Learning: The study of computer algorithms that improve automatically through experience.  Data Mining: This field focuses on the discovery of unknown properties in the data.  Big Data: The use of predictive analysis or other advanced methods to extract value from data (refers seldom to a particular size of data set).  Three V’s: o Volume (amount of data being processed) o Velocity (ability to deal with data arriving very fast) o Variety (data from different sources and with different formats)  Data Science: The creation of models able to extract patterns from complex data and the use of these models in real-life problems.  Model: A generalization obtained from data that can be used afterwards to generate predictions for new given instances.  Method: A systematic procedure that allows to achieve an intended goal.  Algorithm: A step-by-step set of instructions easily understandable by humans.  Hyper-parameter: Values set by the user (e.g., number of clusters in k-means).  Model parameter: Values that are set by a modelling/ learning algorithm in its internal procedure (e.g., slope of a linear regression).Programming for data analysis  General  Many data analysis computations are performed over tabular data à pandas. Data analysis programs are often defined as  • a sequence of transformations • each transformation transforms one DataFrame into another DataFrame.  One-to-one transformation (map): This transformation transforms each row of the DataFrame into another row of a DataFrame. Each transformation can be performed independently.  Many-to-one (reduce) transformation: This transformation transforms multiple rows of the DataFrame into a single row of the new DataFrame. This transformation needs to get the data for all rows to be reduced.  \n",
      " à The transformation from one DataFrame to another is useful, because we can use parallel computing, resulting into a shorter running time.  Pandas  General processing opertations  Load a CSV file into a DataFrame:  § pd.read_csv(“filename”)  Selecting rows based on conditions:  § df [ df [ “header” ] == ”condition” ] For combining multiple conditions use & (and) or | (or)  Selecting columns:  § df [ [ “header_1”, “header_2”, … ] ]  Applying reduce/aggregation function:  § df_name [ “header” ].min() Other functions: max, mean, median, std, …  Series: A series is a sequence of values with an index (like a column of a DataFrame) Converting a series into a DataFrame:  \n",
      "1-to-1 (map) *-to-1 (reduce)§ series.to_frame() à Useful, because many functions return series’ instead of a DataFrame!  Applying different aggregation functions at once:  § df_name.agg( { “header_1” : “min” , “header_2” : “max”, … } )  Applying an aggregation function with (an) entire row(s) as an output § df_name.nsmallest( #rows in output, [ “header” ] ) Similar for nlargest  Grouping and applying reduce/aggregation function per group § df [ [ “header_1”, … ,“header_i”, …, “header_n” ] ].groupby ( [ “header_i” ] ).min()  Combining DataFrames  Sometimes data to be processed is not in a single table / DataFrame. In this case, it is necessary to be able to combine multiple DataFrames. Two of the most useful operations are:  - concat: combines DataFrames by taking rows from each of the DataFrames. § pd.concat( [ DataFrame_1, DataFrame_2 ] )          - join: combines DataFrames by taking columns from each of the DataFrames.  § DataFrame_1.join( DataFrame_2, on = “header”, how = “left” ) The link between the two DataFrames is done by the column specified by on in DataFrame_1 and the index of DataFrame_2Left join: Join every row of the first table with all possible values of the second table. If no matching value exists in the second table, the value will be NaN. \n",
      "  Right join: Join every row of the second table with all possible values of the first table. If no matching value exists in the first table, the value will be NaN. \n",
      "  Inner join: Join every row of the first table with all possible values of the second table. If no matching value exists in the second table, the row will not appear. \n",
      "  Outer join: Join every row of the one table with all possible values of the other. If no matching value exists in the other table, the value in that particular cell will be NaN.Time-series A time-series is a series of values that have a timestamp. a) Univariate: The )me-series has a single feature E.g.: price in a stock index, mortality, birth rate b) Mul,variate: The )me-series has mul)ple features E.g.: Weather (composed by temperature, pressure, humidity, etc.)  Moving Averages In a time-series, it is common that the values are noisy because the observation vary abruptly from point to point (often due to an unprecise observation process) Moving averages are useful in this situation, as they lead to a decrease of that noise. A (simple) moving average of length K computes the average of K values.  Simple Moving Average Normal data[“simpleMA”] = data[“value”].rolling(K, center = False).mean() à rolling transformation allows to create groups of count rows, and apply a reduce/aggregation function to each group.  Centered data[“simpleMA”] = data[“value”].rolling(K, center = True).mean() Note: Pandas has no simple way of computing the centered moving average, as it should, with even number of elements. Solution: It first computes the moving averages, which are assigned to the middle of two elements and then computes the average of the two averages.  Weighted Moving Average Normal The weighted moving average with length K of values, 𝑣!, …, 𝑣\", using weights 𝑤!, …, 𝑤# is defined by weighting the contribution of each element in the window 𝑊𝑀𝐴#(𝑡)=∑𝑤$∗𝑣%&$#$'!∑𝑤$#$'!  data[“weightedMA”] = data[“value”].rolling(K).apply(lambda x: sum(weights*x)/sum(weights)) à “weights” is a list that needs to be defined in advance (e.g.: [1, 2, …, K])  Exponen8al The exponential moving average is a special weighted moving average, where the weighting factors decrease exponentially. 𝐸𝑀𝐴(𝑡)=𝛼𝑣%+𝛼(1−𝛼)𝑣%(!+𝛼(1−𝛼))𝑣%()+⋯,with\t𝛼∈(0,1] data[“EMA”] = data[“value”].ewm(com = 0.2).mean() à Here, 𝛼=!!&*+,.Correla/ons In statistics, correlation is any statistical relationship between two random variables. Correlation is commonly used to refer to the degree to which a pair of variable are linearly related. Note: Correlation does not necessarily mean causality!  Intuition:  • 1: Perfect correla)on – the two variables move in tandem, i.e., in the same direc)on and with a related change • 0: no correla)on • 1: Perfect nega)ve correla)on – when one variable increases, the other decreases with a related change corrVals = dataDF[[“Column1”, “Column2”]].corr()  à ⋱ 𝐶𝑜𝑙𝑢𝑚𝑛1𝐶𝑜𝑙𝑢𝑚𝑛2𝐶𝑜𝑙𝑢𝑚𝑛1 1 𝑥𝐶𝑜𝑙𝑢𝑚𝑛2 𝑥 1  dataDF.corr() à computes the correlation between all the columns of the dataframe.  Shi9ed correla8on Sometimes the correlation is not immediate, but it takes some time (e.g., a person only dies from COVID several days after it has symptoms). Maybe a better correlation can be found by shifting the cases some days to align them with the deaths. à use .iloc  cases = data[[“casesMA”]].iloc[:-12].reset_index(drop = True) à select all but the last 12 rows deaths = data[[“deathsMA”]].iloc[12:].reset_index(drop = True) à select all but the first 12 rows à shiftCorrVal = cases.corrwith(deaths[“deathsMA”])  Parallel and Distributed framework MapReduce: Overview   Sequentially read a lot of data Map phase: Extract the important information Group by key: Sort and shuffle the output of the map phase Reduce phase: Aggregate, summarize, filter or transform Write the result \n",
      "à Programmers only specify the map and reduce functions. The system is responsible for distributed execution, fault-tolerance, etc.  à The map reduce system is responsible for the rest, e.g., partitioning, machine failures…    Both, Map and Reduce tasks can be executed in parallel à good for efficiency & runtime  Issues:  • Need to read and write ﬁles (on mul)ple machines, bc otherwise we might lose data) • Underlying ﬁlesystem replica)on (for writers)• One job must ﬁnish before the next can start Programming with (Apache) Spark Programs using Pandas API are translated into Sparks programs.  Programs are optimized to execute efficiently! Spark programs encode the dependencies among various DataFrames (lineage graph)  Wide-Dependencies: df partition depends on multiple partitions stored on diff. nodes  e.g., groupBy, generic join, select aggregate à computationally expensive! Narrow-Dependencies: df partition depends on data that is co-located (same node)  e.g., simple select, where, co-located join  import pyspark.pandas as ps à importing Pandas API  df = spark.read.option(“header”, True).option(“inferSchema”, True).csv(fileName) df = df.withColumnRenamed(“Educational level”, “EducationalLevel”)  From Spark Dataframe to Spark Pandas Dataframe:  pandas_sparkDF = sparkDF.pandas_api()  From Spark Pandas Dataframe to Spark Dataframe:   sparkDF = pandas_sparkDF.to_spark(index_col = “column”)  Tables and Selection It is possible to create a SQL view/ table from a Spark DataFrame.  Note:  • In SQL, a table stores a set of rows, each one with the same set of columns – null represents a value that does not exist.  • A view is the result of a query – it also contains a set of rows, each one with the same set of columns à Technically, Spark SQL mostly maintains views, as they are the result of queries. For simplicity, we often refer to Spark SQL views as tables  Registering a DataFrame as a SQL table: # Read a CSV file into a DataFrame dfPS = ps.read_cvs(filename)  # Convert Pandas Spark DataFrame into Spark DataFrame dfS = dfPS.to_spark() dfS = dfS.withColumnRenamed(“Eductional level”, “EducationalLevel”) dfS.createOrReplaceTempView(“persons”) à in SQL this DF will be known as “persons”  Executing SQL statements: spark.sql(“statement”)  Selecting columns from a table: SELECT columns FROM table (use * for all columns) à spark.sql(“SELECT * FROM persons”)Selecting rows based on conditions: SELECT columns FROM table WHERE cond1 AND/OR cond2 à spark.sql(“””SELECT * FROM persons         WHERE company == “Good” AND age > 30 ””””)  Create a view from a select result: CREATE OR REPLACE TEMPORARY VIEW table AS SELECT…  Ordering and Limiting the results:  SELECT cols FROM table [WHERE cond][GROUP BY cols][ORDER BY cols][LIMIT num] • GROUP BY groups the rows by the values of the speciﬁed columns.  • ORDER BY allows to order the result by one or more columns. Use “ORDER BY col DESC” for ordering in descending order. • LIMIT allows to return only the ﬁrst N rows in the result.  Aggregation SELECT fun(col), … FROM table [WHERE cond]… Some functions: min, max, mean, percentile(col, 0.5), std, …  Nested Selects It is possible to use the result of a SELECT statement in the definition of another SELECT statement. E.g., the following code computes the number of persons older than Fred. result = spark.sql(“””SELECT count(*) FROM persons         WHERE age > (SELECT age FROM persons WHERE Name = “Fred”) ””””)  Windows (e.g. Moving Average) Spark SQL has no moving average function but it has support for defining windows using the following syntax: Moving_Average = spark.sql(“””SELECT day, value, MEAN(value) OVER     (ORDER BY days ROWS BETWEEN offset PRECEDING AND offset FOLLOWING) AS centerMA FROM data).show()  Note: This is not exactly a moving average, as we get values for every day including the first ones Note: offset can be UNBOUNDED PERCEDING | offset PERCEDING | CURRENT ROW | offset FOLLOWING | UNBOUNDED FOLLOWING  Windows operations can also be performed in different partitions independently – this allows to perform operations over groups  SELECT fun(col1) OVER (PARTITION BY col2 ORDER BY col3 ROWS BETWEEN offset AND offset ) FROM …à This applies fun to values of col1 in the window defined independently in each partition of data, defined by the value of col2 and ordering the partition by col3.  Top-N for each group:  à use nested SELECTs, PARTITION, ORDER BY and RANK youngest = spark.sql(“””SELECT * FROM ( SELECT *, RANK(age) OVER ( PARTITION BY company ORDER BY age ) AS rank FROM persons ) WHERE rank = 1”””)  Join Join rows in table_left with rows in table_right using a condition. Different types of join are supported à INNER | LEFT | RIGHT | CROSS | FULL OUTER  join = spark.sql(“””SELECT * FROM table1 A INNER JOIN table2 B ON A.col = B.col”””) à For referring to table names, it is often convenient to use a smaller name (here A and B)  Miscellaneous Wide and Long format Wide: Each row is a record and each column includes the values of a given variable à pivot Long: Each row is a value of a given variable   à Allows to add new variable without changing the format, which can be beneficial!  à unpivot  Long to wide : df.pivot(index = cols, columns = cols, values = vals) Wide to long : df.melt(id_vars = columns you don’t want to unpivot)  Unstack Unstack “pivots” a level of the row index to the column axis à df.unstack(col) Introduction to Machine Learning There are two classifications of Machine Learning:  1. Supervised learning à We are given a data set and already know what our correct output should look like, having the idea that there is a rela)onship between the input and output à Data includes values to predict (e.g. regression for con)nuous values, classiﬁca)on for discrete classes)  2. Unsupervised learning à Allows us to approach problems with licle to no idea what our results should look like. We can derive structure form data where we don’t necessarily know the eﬀect on the variables à Data does not include the target value. The goal is to ﬁnd structure in the dataSupervised Learning Regression à Trying to predict results within a continuous output, so trying to map input variables to some continuous function.  There are 2 important assumptions in linear regression: • input variables are independent • input variables have a linear relationship with the output variable Linear regression aims to predict a real-valued output based on input values:  𝑦=𝜃!𝑥!+𝜃)𝑥)+⋯+𝜃\"&!, where 𝑥$ is one dimension/input variable of the input space.  •  with one input variable: 𝑦=𝜃!𝑥!+𝜃) (𝜃! and 𝜃) are called weights/parameters)  Let’s assume 𝑦 is a function of 𝑥 plus some error: 𝑦=𝐹(𝑥)+𝜖 We want to approximate 𝐹(𝑋) [the “true” function] with some 𝑔(𝑥,𝜃)=𝜃!𝑥+𝜃) à Find 𝑔(𝑥,𝜃) that minimizes the error à Mean squared error Square error is often written as: 𝔼[𝜃|𝑋]=!)∑M𝑦%−𝑔(𝑥%|𝜃)N)\"%'!  Gradient Descent: à To find the parameters 𝜃! and 𝜃) for 𝑔(𝑥)=𝜃!𝑥+𝜃) that minimize the squared error  𝔼[𝜃|𝑋]=12OM𝑦%−𝑔(𝑥%|𝜃)N)\"\n",
      "%'! . Outline: • Start with some 𝜃! and 𝜃) • Keep changing 𝜃! and 𝜃) to reduce the squared error • Un)l we end up reaching probably a minimum error  à Linear regression, however, only makes sense if the data shows correlation à Otherwise: Try polynomial regression  Polynomial regression:  e.g., 3rd order polynomial regression: 𝑦=𝜃!𝑥-+𝜃)𝑥)+𝜃-𝑥+𝜃.  Overfitting  A statistical model begins to describe the random error in the data rather than the relationship between variables.  A regression model that becomes tailor-made to fit the random quirks of one sample is unlikely to fit the random quirks of another sample à A model that overfits too much one sample will most likely fail with unseen data  Training error: error measured in the training set.      Problem: not a good indicator of the error for new examples     Solution: Measure error outside the training set (estimate true error)Errors Overview Measureable errors: • Training error: error measured in the training data and used to ﬁt the parameters • Test error: error measured on the test data to es)mate the true error  Unmeasurable errors: • True error: expected error for all data • Generaliza,on error: diﬀerence between True error and Training error  Validation and Selection  Holdout method The dataset is separated into two sets, called the training set and the test set.   Problem: Choosing the lowest error on the training set makes the test error biased. The test error is strongly influenced by the data selected for the training and test sets   K-fold cross-valida/on The original data set is divided into k sets. This results in 𝑘 folds. This results in 𝑘 partitions, where for each partition one of the folds is used as the test set and the remaining folds are used as training sets.  à Average of the predictive performances (i.e., error) obtained in each partition  Advantage: By using several partitions, we reduce the chance of having the predictive performance influenced by the partition used and, as a result, have a more reliable predictive performance estimate  Bootstrapping Bootstrapping is used to estimate uncertainty in the parameters Idea: Our data is a representative sample of the universe of possible points. Hence, we can fake resampling that universe by resampling our data. Method: Create replicas by resampling from the data. Create each replica of 𝑁 points by picking at random from the original data. Thus, it can happen that some points will be picked more than one time, some points will be missing, but all replicas should be different. Then, we use each replica as a different experiment to collect statistics.   Wild Bootstrapping Bootstrapping cannot be used for time series, because picking years at random is nonsense à Wild Bootstrapping Idea: True value = predicted value + normally distributed noise with different deviation at each point, for which we use the residuals. Residuals: 𝜖$=𝑦$−𝑦S$ Random variable 𝑛: 𝑛~𝑁(0,1) à standard normal distributed  à Wild Bootstrapping points: 𝑦$∗=𝑦S$+𝜖$𝑛$Ideally, the Residual Plot should be normally distributed 1. Residuals are precy symmetrically distributed, tending to cluster towards the middle of the plot. 2. they’re clustered around the lower single digits of the y-axis (e.g., 0.5 or 1.5, not 30 or 150). 3. in general, there aren’t any clear pacerns. Examples of residual plots that meet previous requirements:    \n",
      "   The logistic model Logistic\tFunction:𝑦=𝐿1+𝑒(#(1(1!)+𝑜  • 𝐿 acts like the limit of the func)on • 𝑘 acts like the slope of the func)on        à the smaller 𝑘 the smoother (less steep) • 𝑥3 acts like the midpoint/turnpoint of the func)on • 𝑜 is the oﬀset of the func)on, so the limit from the leJ  General recipe:  • Specify your cost func)on (e.g., MSE) • Adjust the model parameters to minimize this cost func)on  Exemplary Code:  from scipy.optimize import minimize # Here we are going to use the minimize function   # Logistic Function def logistic(x,x0,L,k):     return L/(1 + np.exp(-k*(x-x0)))  # Cost function - Minimize mean squared error def log_cost(params, data):     x0,L,k,offset = paramspred = logistic(data.iloc[:,0],x0,L,k) + offset     return np.mean( (pred-data.iloc[:,1])**2)  st_params = [1980,1500,0.001,1500] plt.figure(figsize=(10,5)) res=minimize(log_cost,st_params,args=(dataset_df)) x0,L,k,offset = res.x # Best parameters found  # Used the model found (logistic model with a set of parameters and an offset) to predict the values pred = logistic(dataset_df.iloc[:,0],x0,L,k) + offset  # Plot the data and the model built plt.plot(dataset_df.iloc[:,0],dataset_df.iloc[:,1],'.') plt.plot(dataset_df.iloc[:,0],pred)   Multivariate Regression • Mul)ple linear regression: 𝑦=𝜃!𝑥!+𝜃)𝑥)+⋯+𝜃\"𝑥\"+𝜃\"&! • Mul)ple non-linear regression: 𝑦=𝜃!𝑥!+𝜃)𝑥!)+𝜃-𝑥)+𝜃.𝑥))+𝜃4  Regression Summary Why fit a regression model? à Fit a theoretical model to understand relations • Measuring error is necessary to es)mate the quality of the ﬁt • Bootstrapping (or wild) is useful for es)ma)ng uncertainty of the parameters  Interpolation: predict new values within the range of the data • Need a test set for es)ma)ng error outside the training set • If selec)ng model, more reliable to es)mate true error with cross valida)on  Note: For now ignore the influence of categorial varibales.  Regularization Change learning algorithm to reduce overfitting by constraining the model à Ridge regression 𝐽(𝜃)=∑[𝑦%−𝑔(𝑥%|𝜃)])+𝜆∑𝜃5),5'!\"%'!       Normal regression penalty term  By introducing the penalty term, we force the magnitude of 𝜃 to be smaller.Code:           Result: \n",
      "    Note: in the code alpha represents the 𝜆 in the function above. Note: The result is based on the best alpha. With this we compute the model based on training set  Dimensionality Reduction Assume you have many features and want to categorize your data. One way would be to plot histograms and scatterplots in order to see the relation between the features for each class. This approach, however, is tedious.   Principal Component Analysis (PCA) à Taking a high dimensional data set and reducing it to low dimensional graph PCA is a linear dimensionality reduction technique, which performs a linear mapping of the data to a lower-dimensional space in such a way that the variance of the data in the low-dimensional representation is maximized. It tries to preserve the essential parts that have more variation of the data and remove the non-essential parts with fewer variation. Example graph: \n",
      "       à Useful for identifying patterns and similarities in the data. By revealing how variables are correlated and how data points are grouped, PCA can highlight inherent similarities among observations in a dataset  Might not work in some cases: • Highest variance components may not be most useful • The number of components we want may not capture most variance • Linear transforma)on may not be enough  \n",
      "#features \n",
      "MSE \n",
      "PC1 \n",
      "PC2 \n",
      "Notes: - The values of PC1 and PC2 do not have an interpreta)on - The PC1 axis is more important than the PC2 axis in terms of similarityt-Distributed Stochas/c Neighbor Embedding (tSNE) tSNE is a non-linear technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. It minimizes the divergence between two distributions: a distribution that measures pairwise similarities of the input objects and a distribution that measures pairwise similarities of the corresponding low-dimensional points.  Classification Classes are linearly separable if they can be separated by some linear combination of feature values (a hyperplane). The frontier is a linear discriminant.  Hyperplane: A subspace whose dimension is one less than that of its ambient space, i.e. if space ∈𝑅), a hyperplane is a line, if space ∈𝑅-, a hyperplane is a plane, …  Linear Discriminant: The frontier is given by the function 𝑦(𝑥⃗)=𝑤dd⃗6𝑥⃗+𝑤3 that is positive on one side of the hyperplane and negative on the other, i.e. one class is positive, the other is negative.  Note: Fitting with the MSE does not lead to good results, because this pulls the discriminant towards distant points.  à Logistic Regression:  Logistic Regression is a statistical method for predicting binary classes. Assume there is a function 𝑔(𝑥⃗,𝑤e)=𝑃(𝐶!|𝑥⃗), where 𝑥⃗ is the vector of features and 𝑤e represents the weights or coefficients that the logistic regression model learns during training. 𝑃(𝐶!|𝑥⃗) is the probability of the instance belonging to class 1 and we want to find a discriminant so that 𝑃(𝐶!|𝑥⃗)=𝑃(𝐶)|𝑥⃗). à Based on the features we choose the class with larger estimated probability. à The function 𝑔 is typically the sigmoid function/logistic function: !!&7\"#.  Assuming 𝑔(𝑥⃗,𝑤e)=𝑃(𝐶!|𝑥⃗), this implies that the plane is:  𝑃(𝑦=1|𝑥;𝜃)=1−𝑃(𝑦=0|𝑥;𝜃)  Further,  𝑔(𝑥⃗,𝑤e)= 11+𝑒((899⃗$1⃗&8!)  The parameters 𝑤dd⃗ are found by maximum likelihood.   Regression vs. Classification: Regression: Fit the data as closely as possible to predict continuous values Classification: Find discriminant between discrete classesMaximum margin classiﬁer Margin: A margin is the distance between the hyperplane and the nearest data point from either class. The goal of SVM is to choose a hyperplane with the greatest possible margin between the hyperplane and any point within the training data, offering a buffer that helps correctly classify new data points.  Margin classifier: A classifier that provides the distance to the discriminant, i.e. the hyperplane separating the classes is a linear classifier.  Maximum Margin Classifier: Finds the maximum-margin discriminant maximizing the distance to the nearest points to separate. à Reduces overfitting by constraining the frontier  Problem: Difficult to compute because of discontinuity  Kernel Trick Kernel: transforms an input data space into the required form. Kernel trick: The kernel takes a low-dimensional input space and transforms it into a higher dimensional space. Within this higher-dimensional space, the classes are “linearly” separable. This separation is then transformed back to the initial lower-dimensional input space. • Linear Kernel • Polynomial Kernel (can dis)nguish curved or nonlinear input space) • Radial Basis Func)on Kernel (can map input space in inﬁnite dimensional space)  Unsupervised Learning Classification vs. clustering Classification Clustering • Class labels are part of the data • Classes used in training, generally to predict labels for addi)onal data • “Classes” (clusters) are unknown and inferred by the model • Although descrip)ve of the data structure, clusters are used to predict classes Clustering Basic idea: Group similar examples together • Min diﬀerence (or max similarity) within clusters • Max diﬀerence (or min similarity) between clusters • Clustering requires some measure of similarity  Why do we need clustering? à To help understand data and relations!  What can we do with clustering? • Find useful classes of examples • Find outliers • Find rela)ons between en))es and groups (e.g. hierarchical clustering)• Summarize data Partitional Clustering: Data is divided into groups at the same level Hierarchical clustering: Clusters are nested within larger clusters in a tree  Exclusive clustering: Each example belongs to only one cluster Overlapping clustering: Examples may belong to more than one cluster Fuzzy clustering: Each example belongs to clusters with 𝑤#=[0,1] Probabilistic clustering: each example belongs to clusters with 𝑤#=[0,1], where ∑𝑤#=1#   Complete clustering: All examples are assigned to cluster(s) Partial clustering: Some examples remain unassigned (e.g. noise, irrelevant data, etc.)  Types of clustering Prototype-based Contiguity-based Density-based  Define a (set) of prototype(s) for each cluster. Examples belong to the cluster that has the closest prototype \n",
      " Closer in cluster than outside  High-density regions, discarding noise \n",
      "    Algorithms: K-means Problem to solve: Find the best clustering of 𝐾 clusters • Deﬁne clusters by proximity to the mean of the cluster • The number of centroids and clusters is predeﬁned à Partitional, exclusive, complete and prototype based  Pseudocode:  Start with 𝐾 centroids Loop • Assign each example to closest centroid • Update centroid to mean of respec)ve cluster • Recompute clusters • Repeat un)l convergence / or given number of itera)ons is reached  K-means initialization: What should be the initial 𝐾 centroids? • Random: Start with the coordinates of 𝐾 random elements • Forgy: Randomly assign elements to par))ons and use the centroids of each par))on à According to literature, the random approach is betterK-means distance: Different distance measures can be used. Euclidean is usually used, but Minkowsky is more general: 𝐷(𝑥,𝑦)=jO|𝑥;−𝑦;|<; \t\t%  Clustering valida/on: SilhoueKe Score Silhouette score measures how close an element is to its own cluster (cohesion) compared to other clusters (separation). For element i: • 𝑎(𝑖): average of distance of 𝑖 to all points in the same cluster • 𝑏(𝑖): average of distance of 𝑖 to all points in the nearest cluster (lowest average distance) 𝑠(𝑖)=𝑏(𝑖)−𝑎(𝑖)max\t(𝑎(𝑖),𝑏(𝑖))  • 𝑠(𝑖)=[−1,1]: The higher the score, the more appropriately point 𝑖 is clustered • Silhouece coeﬃcient is the mean of Silhouece Scores of all elements  Number of clusters The number of cluster is a parameter for K-means When 𝐾 is unknown, the following strategy is often used: • Compute the clustering for diﬀerent values of 𝐾; • Find the 𝐾 with best quality / where quality stops improving fast. When using the Silhouette coefficient, this is often known as Silhouette analysis  Clustering @Spark Where can distributed processing frameworks help? • Data size o K-means: Compu)ng the sum for subsets, by keeping track of size of subset  [sum, count] \n",
      "  o Each machine only needs to load a par))on of the data – helps suppor)ng larger data sets o Each machine only does a subset of the computa)ons – faster computa)ons  • Number of models o Use diﬀerent algorithms for training and experiment which works becer – faster computa)onso Compute diﬀerent models for the same algorithm in parallel – faster computa)ons Graph Algorithms A graph is a structure composed by vertices and edges. Edges can be both, directed and undirected. Graphs with directed edges, arcs, are called directed graphs. Graphs, that have edges with associated values are called weighted graphs.  Dijkstra – Shortest Path Problem When to use: Non-negative arc lengths with a specific starting point \n",
      " à Don’t stop once you have the first value for a path to 𝑡 but only stop when you look at 𝑡.  Compute importance of web pages – PageRank Key ideas: • The more links to a page, the more important it is• Importance of links depends on the source page  Intuition: In each step, each node propagates to neighbors its page rank, divided by the number of edges. The page rank of a node is (with 𝑅[𝑖] the page rank of page 𝑖): 𝑅[𝑖]=0.15+0.85O𝑅[𝑗]Outlinks(𝑗)5∈>?@ABCDE(5)  e.g.: \n",
      "    à Iterate until convergence (or until changes are small)  Connected components Find out connected components in a graph Connected component: A subset pf vertices, for which any pair of vertices is connected directly or indirectly and no vertex is connected with any other node outside of the component  Use cases:  • Find related people in e-commerce sites: o All people using the same address, credit card, etc.  Community detec/on Often networks are organized into clusters, communities Goal: Find densely linked clusters  Use-cases:  • Discovering social circles • Customer Segmenta)on • Recommender systems  Maximum-Flow Computes the maximum flow between two vertices • Use-cases: Match makingGraphs in Spark Creating an edge: à must have columns src, dest. Can also have additional columns that can be used in queries \n",
      "  Creating a vertex: à must have a column id(entifier). Can also have additional properties. \n",
      "  Creating a graph: \n",
      "  Introduction to cloud-based Data Analysis ecosystems  CPUs, GPUs, TPUs and data analysis The central processing unit (CPU) is the main processor of a computer and runs generics instructions. It is responsible for executing the code of programs. • A CPU runs one instruc)on at a )me • Modern processors include many CPUs (or cores)  A graphics processing unit (GPU) is a specialized processor designed to accelerate the creation of images.  • Modern GPUs may include thousands of cores, with each one execu)ng the same opera)on at the same )me on diﬀerent data  A tensor processing unit (TPU) is a specialized processor designed by Google to accelerate AI processing, specifically neural networks machine learning. It is similar to a GPU, but optimized to do matrix operations (which are the base of neural networks) • Recent TPUs have tens of thousands of units that execute opera)ons in parallel.à Parallel processing speeds data analysis up!     Data analysis/processing models Data analysis/processing tasks consist in executing computations over data Two main data processing models: 1. Batch processing consist in performing computa)ons over a dataset that is available when the computa)on starts à Goal: Execute computation over data and produce result. All data must be known when processing starts Note: For different data analysis processes data will be in different data storage systems and after processing data must be stored in some data storage system. 2. Stream processing consists in doing con)nuous computa)ons over data that is being created/received.  o Need to process data as it arrives o Need to be able to process data from mul)ple sources o Need to tolerate faults  a. Con)nuous § Each tuple processed as it arrives b. Mini-batch § Tuples received for each X ms grouped in a mini-batch and then process mini-batches à When doing stream processing, it is oJen interes)ng to compute results based on data from a given interval, but compute results more frequently than this )me interval.  Stream processing systems typically load streaming data from intermediate publish-subscribe (PS) systems; results can be stores in ﬁles, databased or presented in dashboards.  Data storages I. Blob stores o Used to store large data “ﬁles” § Immutable § Append-only o Inexpensive storage o Common uses: Read/write the whole ﬁle, logs, etc. II. Rela)onal (SQL) databases o Used to store structured data - tabels o More expensive than blob storage o Common uses: Queries, updates to rows in tables, store general applica)on dataIII. Key-value stores / Document databases o Used to store structured data – document (more scalable than SQL databases) o More expensive than blob stores and rela)onal (SQL) databases o Mul)ple storage servers around the world (more secure) o Common uses: Queries, updates to documents, store general applica)on data  I. Graph database à store graph-based data II. Analy)cal stores à Keeps a copy of the db used by user-facing services, to allow data analysis without impac)ng running services.  Data processing platforms often include specialized distributed file systems, designed to support efficient data parallel processing.  Time-series databases:  Database specially designed to process time-series in real-time.  Goal: applications often want to detect state transitions – e.g. from working correctly to incorrectly Challenges:  • Speed is more important than full accuracy • Impossible to store all data Privacy-preserving Data Analysis Security of data in public cloud Concerns regarding security/privacy:  • Loca)on of data (diﬀerent countries have diﬀerent laws regarding data) o Cloud plauorms typically allow users to specify which data centers to use for storing data and for execu)ng computa)ons (not all: e.g. free Google Colab)  Large cloud providers implement encryption at rest for customers’ data, by default  Encryption at Rest: Whenever data is stored on disks, the data will be encrypted. Several layers of encryption occur. • Impossible to access data without encryp)on key • Considered a best prac)ce to meet regulatory requirements: GDPR, HIPAA • Security in case of remote or physical access to disks  à When using the cloud, one needs to be careful which data centers will be used for storing data and performing computations à Cloud providers provide encryption at rest for improving security and privacy of data  Privacy-preserving data sharing Anonymize: Guarantees that form the anonymized data it is not possible to identify the original data (typically worried about identifying the individuals/ subject of the data).K-anonymity Quasi-identifier: A set of attributes that, when combined, can lead to the identification of individuals/subjects.  A dataset is k-anonymous if, for each unique combination of quasi-identifiers, there are at least k-1 other individuals with the same combination.   Suppression: Removing certain values from the dataset  Generalization: Replacing specific values with more general or less precise values Bucketization: Grouping values into buckets to achieve anonymity. Other techniques: • Data swapping: Changing values between similar samples • Noise addi,on: Adding noise to values (e.g. change the age of a sample from 22 to 23)  Differential privacy Differential privacy algorithm: Guarantees that by observing a result that includes the data for some user, it is impossible to learn more about the user than by observing the result without the data from that user. Car example (average speed): Each car adds some random noise to its speed. Problem: If each car sends its speed multiple times, one can find out its speed.  LaPlace mechanism: Adding the noise with a pdf from the LaPlace distribution Gaussian mechanism: Adding the noise with a pdf from the Gaussian distribution à Both mechanisms cannot be used with categorical variables  Randomized mechanism: Adding uncertainty to the value reported, i.e. reporting the real value with a given probability; otherwise a random value is reported.   Privacy for statistical information: • Counts, averages, etc.,  • Histograms,  • CDFs, • Clustering,  • Classiﬁca)on, and many more…  Question: Compute the average of Uber driver tips, but drivers don’t wan to disclose their tips. Question: Compute how frequent the use of credit cards was   Privacy-preserving computation Multi-party computation We have multiple parties that do not trust each other. They want to compute some function of their collective inputs, without revealing the inputs to others.  • Single central en)ty in which par)es trustà Send the value to central en)ty & it announces\n",
      "------------\n",
      "\n",
      "Create questions that will prepare the student for their exam.\n",
      "Make sure not to lose any important information.\n",
      "\n",
      "QUESTIONS:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert at creating practice questions based on study material.\n",
      "Your goal is to help a student prepare for an exam.\n",
      "We have received some practice questions to a certain extent: Okay, here are some practice questions based on the provided study notes, designed to cover the key concepts and prepare a student for an exam on Advanced Data Analytics:\n",
      "\n",
      "**Introduction to Big Data:**\n",
      "\n",
      "1.  What are the four key actions needed to extract knowledge and value from data, according to the introduction?\n",
      "2.  Explain the difference between Data Mining and Big Data, as defined in the text.\n",
      "3.  Describe the \"Three V's\" of Big Data and provide a brief explanation of each.\n",
      "4.  Define what a \"Model\" is in the context of data science.\n",
      "5.  Explain the difference between an Algorithm and a Method.\n",
      "6.  What is the difference between a hyper-parameter and a model parameter? Give an example of each.\n",
      "\n",
      "**Programming for Data Analysis (Pandas & Spark):**\n",
      "\n",
      "7.  In Pandas, what is a one-to-one transformation (map)? Why is it useful for parallel computing?\n",
      "8.  What is a many-to-one transformation (reduce) in Pandas? What is a limitation of this transformation regarding parallel computing?\n",
      "9.  Write the Pandas code to load a CSV file named \"data.csv\" into a DataFrame.\n",
      "10. Write the Pandas code to select rows from a DataFrame called `df` where the \"status\" column is equal to \"completed\" AND the \"value\" column is greater than 10.\n",
      "11. Write the Pandas code to select only the \"name\" and \"age\" columns from a DataFrame called `df`.\n",
      "12. Write the Pandas code to calculate the mean of the \"salary\" column in a DataFrame called `employee_data`.\n",
      "13. What is a Pandas Series? How can you convert a Series into a DataFrame, and why might you want to do that?\n",
      "14. Write the Pandas code to apply both the \"min\" function to \"header_1\" and the \"max\" function to \"header_2\" of the DataFrame called `df_name`.\n",
      "15. Write the Pandas code to display the 5 rows with the smallest values in the \"price\" column of a DataFrame called `products`.\n",
      "16. Write the Pandas code to group a DataFrame called `sales` by the \"region\" column and then calculate the sum of the \"amount\" for each region.\n",
      "17. Explain the difference between `concat` and `join` operations in Pandas for combining DataFrames.\n",
      "18. Describe what a left join, right join, inner join, and outer join do.\n",
      "19. Write the Pandas code to concatenate two DataFrames, `df1` and `df2`.\n",
      "20. Write the Pandas code to perform a left join between `df1` and `df2` on the column \"ID\", assuming \"ID\" is a regular column in `df1` and the index in `df2`.\n",
      "21. What is a time-series? What is the difference between a univariate and a multivariate time-series?\n",
      "22. Explain the purpose of using moving averages in time-series analysis.\n",
      "23. Write the Pandas code to calculate a simple moving average with a window of size 5 on the \"sales\" column of a DataFrame called `time_series_data`, without centering.\n",
      "24. Explain how to compute a centered moving average in Pandas when the number of elements is even.\n",
      "25. Explain the formula for the weighted moving average.\n",
      "26. Write the Pandas code to calculate an exponential moving average (EMA) with `com=0.2` on the \"stock_price\" column of a DataFrame called `stock_data`.\n",
      "27. Explain what correlation is and what it means if two variables have a correlation of 1, 0, and -1.\n",
      "28. What does correlation not imply?\n",
      "29. Explain the concept of shifted correlation and why it might be useful.\n",
      "30. Briefly describe the MapReduce framework. What are the key phases? What is the role of the programmer in this framework?\n",
      "31. What are the issues with MapReduce?\n",
      "32. What is a lineage graph in Spark?\n",
      "33. Explain the difference between wide and narrow dependencies in Spark and give examples of operations that create each type of dependency.\n",
      "34. Write the PySpark code to read a CSV file named \"data.csv\" into a Spark DataFrame, infer the schema, and rename the column \"old_name\" to \"new_name\".\n",
      "35. Write the PySpark code to convert a Spark DataFrame called `spark_df` to a Spark Pandas DataFrame.\n",
      "36. Write the PySpark code to convert a Spark Pandas DataFrame called `pandas_spark_df` to a Spark DataFrame, using \"ID\" as the index column.\n",
      "37. How do you register a Spark DataFrame as a SQL table? Give an example.\n",
      "38. Write the Spark SQL query to select all columns from a table named \"customers\" where the \"city\" is \"New York\" OR the \"age\" is less than 30.\n",
      "39. Write the Spark SQL query to create a temporary view named \"young_customers\" from a SELECT statement that retrieves customers younger than 25 from the \"customers\" table.\n",
      "40. Write the Spark SQL query to select the maximum \"salary\" from the \"employees\" table, grouped by \"department\".\n",
      "41. Write the Spark SQL query to select the top 3 highest-paid employees from the \"employees\" table.\n",
      "42. Explain how to perform moving average calculations using Spark SQL windows.\n",
      "43. Write the Spark SQL query to find the youngest person in each company, using nested SELECTs, PARTITION, ORDER BY, and RANK.\n",
      "44. Write the Spark SQL query to perform an inner join between \"orders\" and \"customers\" tables on the \"customer_id\" column.\n",
      "45. Explain the difference between wide and long data formats and when each might be preferred.\n",
      "46. What is the purpose of the `unstack` function in Pandas?\n",
      "\n",
      "**Introduction to Machine Learning:**\n",
      "\n",
      "47. What is the difference between supervised and unsupervised learning? Give an example of each.\n",
      "48. Explain the goal of regression in supervised learning.\n",
      "49. What are the two important assumptions in linear regression?\n",
      "50. Explain the equation: 𝑦=𝜃!𝑥!+𝜃). What do 𝜃! and 𝜃) represent?\n",
      "51. What is the goal of linear regression?\n",
      "52. What is Gradient Descent and how is it used in linear regression?\n",
      "53. What is polynomial regression and when might it be used instead of linear regression?\n",
      "54. Define overfitting. Why is it a problem?\n",
      "55. Explain the difference between training error, test error, true error, and generalization error.\n",
      "56. Describe the holdout method for validation and selection. What is a problem with this method?\n",
      "57. Explain K-fold cross-validation. What is the advantage of using it?\n",
      "58. Explain the bootstrapping method.\n",
      "59. Why can't bootstrapping be used for time series?\n",
      "60. Explain wild bootstrapping.\n",
      "61. What are the characteristics of a residual plot that is normally distributed?\n",
      "62. Explain the logistic function. What do L, k, x0, and o represent?\n",
      "63. What is regularization and how does it help prevent overfitting?\n",
      "64. Explain Ridge regression.\n",
      "65. What is dimensionality reduction and why is it useful?\n",
      "66. Explain Principal Component Analysis (PCA). What does it try to preserve?\n",
      "67. What are the limitations of PCA?\n",
      "68. Explain t-Distributed Stochastic Neighbor Embedding (t-SNE).\n",
      "69. What does it mean if classes are linearly separable?\n",
      "70. What is a hyperplane?\n",
      "71. What is a linear discriminant?\n",
      "72. Explain logistic regression.\n",
      "73. What is the sigmoid function/logistic function?\n",
      "74. What is a maximum margin classifier?\n",
      "75. What is a kernel trick?\n",
      "76. What is the goal of clustering?\n",
      "77. What are the different types of clustering?\n",
      "78. Explain the K-means algorithm.\n",
      "79. What is the Silhouette Score and how is it used for clustering validation?\n",
      "80. Explain how distributed processing frameworks help with clustering.\n",
      "\n",
      "**Graph Algorithms:**\n",
      "\n",
      "81. What is a graph composed of?\n",
      "82. When should you use Dijkstra's algorithm?\n",
      "83. Explain the key ideas behind PageRank.\n",
      "84. What is a connected component?\n",
      "85. What are the use cases for community detection?\n",
      "86. What are the use cases for maximum-flow?\n",
      "\n",
      "**Cloud-Based Data Analysis Ecosystems:**\n",
      "\n",
      "87. What is the difference between a CPU, GPU, and TPU? Which is best suited for data analysis and why?\n",
      "88. Explain the difference between batch processing and stream processing.\n",
      "89. What are the different types of data storages?\n",
      "90. What is encryption at rest?\n",
      "\n",
      "**Privacy-Preserving Data Analysis:**\n",
      "\n",
      "91. What are the concerns regarding security/privacy?\n",
      "92. What is K-anonymity?\n",
      "93. What is differential privacy?\n",
      "94. Explain multi-party computation.\n",
      ".\n",
      "We have the option to refine the existing questions or add new ones.\n",
      "(only if necessary) with some more context below.\n",
      "------------\n",
      " Adding the noise with a pdf from the LaPlace distribution Gaussian mechanism: Adding the noise with a pdf from the Gaussian distribution à Both mechanisms cannot be used with categorical variables  Randomized mechanism: Adding uncertainty to the value reported, i.e. reporting the real value with a given probability; otherwise a random value is reported.   Privacy for statistical information: • Counts, averages, etc.,  • Histograms,  • CDFs, • Clustering,  • Classiﬁca)on, and many more…  Question: Compute the average of Uber driver tips, but drivers don’t wan to disclose their tips. Question: Compute how frequent the use of credit cards was   Privacy-preserving computation Multi-party computation We have multiple parties that do not trust each other. They want to compute some function of their collective inputs, without revealing the inputs to others.  • Single central en)ty in which par)es trustà Send the value to central en)ty & it announces the result Issue: The central en)ty knows the values and can leak them • Mul)ple central en))es that do not collude à Each party splits its value and send a one part to each central en)ty. Final result is the sum of par)al sums of each central en)ty Issue: What if the central en))es collude? • No central en)ty à First node send its value + large random value; other nodes add their value. Upon receiving the value, the ﬁrst node subtract the random and announces the result Issue: If x1 and x3 collude, they can know about x2. • Combina)on of 2nd and 3rd bullet:  o Each party splits its value into shares and distributes them to the others. o Party 1 adds a random value to its sum and sends it to Party 2. o Each subsequent party adds its sum of received shares to the value received and passes it on. o The ﬁnal value from Party N is sent back to Party 1. o Party A subtracts the random value and announces the total sum.  Note: General purpose multi-party computation is slow.  Homomorphic encryption Motivation: Consider you want to store data in the cloud, but data must remain private. Note, you also want to be able to make changes.  à Encrypt data – upload data – changes – download data – decrypt data – make changes – encrypt data – upload data is too slow! à What we need: Be able to execute computations over encrypted data  Homomorphic encryption is a form of encryption that allows computations to be performed on encrypted data without first having to decrypt it.  Partially homomorphic encryption: Work only with a single operation E.g. (RSA) 𝐸(𝑚)=𝑚7𝑚𝑜𝑑\t𝑛→𝐸(𝑚!)∗𝐸(𝑚))=𝑚!7𝑚)7\t𝑚𝑜𝑑\t𝑛=(𝑚!∗𝑚))7\t𝑚𝑜𝑑\t𝑛=𝐸(𝑚!∗𝑚))\t  à Multiplying the encrypted value of 𝑚! and 𝑚) is equal to encrypting the value of the product of 𝑚! and 𝑚).  There are multiplicative (ElGammal) and additive (Paillier) partial homomorphic encryptions.  A full homomorphic encryption was discovered in 2008 by Craig Gentry.  Partial homomorphic encryption: Not too slow. Full homomorphic encryption: Very slow.\n",
      "------------\n",
      "\n",
      "Given the new context, refine the original questions in English.\n",
      "If the context is not helpful, please provide the original questions.\n",
      "QUESTIONS:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "questions_text = generate_questions(docs_q, provider = \"gemini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08241e77",
   "metadata": {},
   "source": [
    "## Generating Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef911dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760975821.509791  183747 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760975823.562235  183747 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  1.  Define \"Analytics\" as described in the notes. What are the four key characteristics of patterns and models discovered through analytics?\n",
      "Answer:  Analytics: The science that analyzes crude data to extract useful knowledge from them.\n",
      "\n",
      "The four key characteristics of patterns and models discovered through analytics are:\n",
      "\n",
      "1.  Valid: hold on new data with some certainty\n",
      "2.  Useful: should be possible to act on the item\n",
      "3.  Unexpected: non-obvious to the system\n",
      "4.  Understandable: humans should be able to interpret the pattern\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  2.  Explain the difference between Data Mining and Data Science, according to the notes.\n",
      "Answer:  Data Mining: This field focuses on the discovery of unknown properties in the data.\n",
      "Data Science: The creation of models able to extract patterns from complex data and the use of these models in real-life problems.\n",
      "\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  3.  What are the \"Three V's\" of Big Data, and why are they important?\n",
      "Answer:  The \"Three V's\" of Big Data are:\n",
      "\n",
      "*   **Volume:** The amount of data being processed.\n",
      "*   **Velocity:** The ability to deal with data arriving very fast.\n",
      "*   **Variety:** Data from different sources and with different formats.\n",
      "\n",
      "These are important because they characterize the challenges and opportunities associated with Big Data. Dealing with large volumes of data, high data arrival rates, and diverse data formats requires specialized techniques and technologies for effective storage, management, and analysis.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  4.  Differentiate between a Model, a Method, and an Algorithm.\n",
      "Answer:  Here's the breakdown of the differences between a Model, a Method, and an Algorithm:\n",
      "\n",
      "*   **Model:** A generalization obtained from data that can be used to generate predictions for new, given instances.\n",
      "\n",
      "*   **Method:** A systematic procedure that allows one to achieve an intended goal.\n",
      "\n",
      "*   **Algorithm:** A step-by-step set of instructions easily understandable by humans.\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  5.  What is the difference between a hyper-parameter and a model parameter? Give an example of each.\n",
      "Answer:  Here's the breakdown of the difference between hyperparameters and model parameters, along with examples:\n",
      "\n",
      "*   **Model Parameter:** Values that are set by a modelling/ learning algorithm in its internal procedure (e.g., slope of a linear regression).\n",
      "*   **Hyper-parameter:** Values set by the user (e.g., number of clusters in k-means).\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  6.  Describe the difference between a one-to-one (map) transformation and a many-to-one (reduce) transformation in the context of DataFrame manipulation. Why is the transformation from one DataFrame to another useful?\n",
      "Answer:  Here's the breakdown of the difference between one-to-one (map) and many-to-one (reduce) transformations in DataFrame manipulation, along with the usefulness of DataFrame transformations:\n",
      "\n",
      "*   **One-to-one (map) transformation:** This transforms each row of a DataFrame into another row of a new DataFrame. Each transformation can be performed independently of other rows.\n",
      "\n",
      "*   **Many-to-one (reduce) transformation:** This transforms multiple rows of a DataFrame into a single row in a new DataFrame. This type of transformation requires data from multiple rows to be aggregated or combined.\n",
      "\n",
      "**Usefulness of DataFrame transformation:**\n",
      "\n",
      "The transformation from one DataFrame to another is useful because it enables parallel computing. By breaking down the data processing into a sequence of DataFrame transformations, each transformation can be executed in parallel, potentially leading to a significant reduction in running time, especially for large datasets.\n",
      "\n",
      "--------------------------------------------------\\n\\n\n",
      "Question:  7.  Write the Pandas code to load a CSV file named \"data.csv\" into a DataFrame.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:75\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/grpc/_channel.py:1195\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m state, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1193\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1194\u001b[0m )\n\u001b[0;32m-> 1195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/grpc/_channel.py:1009\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"The model is overloaded. Please try again later.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2a00:1450:4016:809::200a%5D:443 {grpc_status:14, grpc_message:\"The model is overloaded. Please try again later.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:77\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: 503 The model is overloaded. Please try again later.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m create_vector_store(docs_a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Generating answers\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mretrieve_answers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquestions_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/src/generating_answers.py:118\u001b[0m, in \u001b[0;36mretrieve_answers\u001b[0;34m(questions, vector_store, provider, model, temperature)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m question_list:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;124m\"\u001b[39m, question)\n\u001b[0;32m--> 118\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43manswer_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;124m\"\u001b[39m, answer)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------------------------------\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:193\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     emit_warning()\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/base.py:627\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    628\u001b[0m         _output_key\n\u001b[1;32m    629\u001b[0m     ]\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    633\u001b[0m         _output_key\n\u001b[1;32m    634\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:193\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     emit_warning()\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/base.py:410\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    408\u001b[0m }\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/base.py:165\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    164\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 165\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    170\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    171\u001b[0m         inputs,\n\u001b[1;32m    172\u001b[0m         outputs,\n\u001b[1;32m    173\u001b[0m         return_only_outputs,\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:159\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_source_documents:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: answer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs}\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:193\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     emit_warning()\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/base.py:632\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    628\u001b[0m         _output_key\n\u001b[1;32m    629\u001b[0m     ]\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    633\u001b[0m         _output_key\n\u001b[1;32m    634\u001b[0m     ]\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    637\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    640\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:193\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     emit_warning()\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/base.py:410\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    408\u001b[0m }\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/base.py:165\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    164\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 165\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    170\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    171\u001b[0m         inputs,\n\u001b[1;32m    172\u001b[0m         outputs,\n\u001b[1;32m    173\u001b[0m         return_only_outputs,\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:143\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    142\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 143\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py:263\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/llm.py:325\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:193\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     emit_warning()\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/base.py:410\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    408\u001b[0m }\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/base.py:165\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    164\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 165\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    170\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    171\u001b[0m         inputs,\n\u001b[1;32m    172\u001b[0m         outputs,\n\u001b[1;32m    173\u001b[0m         return_only_outputs,\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/llm.py:127\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    124\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    125\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 127\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain/chains/llm.py:139\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    146\u001b[0m     cast(\u001b[38;5;28mlist\u001b[39m, prompts),\n\u001b[1;32m    147\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks},\n\u001b[1;32m    148\u001b[0m )\n\u001b[1;32m    149\u001b[0m generations: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Generation]] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1025\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1023\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m   1024\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:842\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    841\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 842\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m         )\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    850\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1091\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1091\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1095\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:946\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    922\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    934\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m    935\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    936\u001b[0m         messages,\n\u001b[1;32m    937\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m    945\u001b[0m     )\n\u001b[0;32m--> 946\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/tenacity/__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/tenacity/__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/tenacity/__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/tenacity/__init__.py:400\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/tenacity/__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    293\u001b[0m )\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Additional Education/study_buddy/study_buddy_venv/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:167\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m next_sleep \u001b[38;5;241m=\u001b[39m _retry_error_helper(\n\u001b[1;32m    157\u001b[0m     exc,\n\u001b[1;32m    158\u001b[0m     deadline,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     timeout,\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_sleep\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vector_store = create_vector_store(docs_a, \"gemini\")\n",
    "\n",
    "# Generating answers\n",
    "retrieve_answers(\n",
    "    questions = questions_text,\n",
    "    vector_store = vector_store, \n",
    "    provider = \"gemini\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study_buddy_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
